{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Feature Extractor\n",
    "\n",
    "1. **Objective**: Implements a feature extractor using a pretrained `ResNet50` model.\n",
    "2. **Pretrained Model**: Leverages `ResNet50` with weights pre-trained on the ImageNet dataset for transfer learning.\n",
    "3. **Feature Extraction**: Excludes the final classification layer by using all layers except the last (`[:-1]`).\n",
    "4. **Output Format**: The extracted feature map is reshaped to a 2D tensor with dimensions `(batch_size, -1)` for downstream tasks.\n",
    "5. **Applications**: Useful for tasks like image similarity, clustering, and as input to additional layers or models.\n",
    "6. **Key Advantage**: Simplifies the extraction of high-dimensional image features from a robust pretrained architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pretrained ResNet Model\n",
    "\n",
    "class ResNetFeatureExtractior(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetFeatureExtractior,self).__init__()\n",
    "        resnet = resnet50(pretrained = True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "    def forward(self,x):\n",
    "        x = self.feature_extractor(x)\n",
    "        return x.view(x.size(0),-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetFeatureExtractior()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Feature Extraction with Additional Hidden Layer\n",
    "\n",
    "1. **Objective**: Enhances the `ResNet50` model by adding a hidden layer, ReLU activation, and dropout to refine feature embeddings.\n",
    "2. **Feature Extractor**: Utilizes the pretrained `ResNet50` architecture, excluding the final classification layer.\n",
    "3. **Additional Layer**:\n",
    "   - Linear layer: Maps 2048-dimensional features to a custom embedding dimension (`embedding_dim`).\n",
    "   - ReLU: Adds non-linearity for better feature representation.\n",
    "   - Dropout: Prevents overfitting by randomly dropping 50% of neurons during training.\n",
    "4. **Embedding Generation**: The model outputs a reduced-dimension feature embedding for each input image.\n",
    "5. **Customization**: Embedding dimension (`embedding_dim`) can be adjusted based on application requirements.\n",
    "6. **Key Use Case**: Ideal for applications like image similarity, retrieval, and clustering with refined embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pretrained ResNet Model with one hideen layer and ReLU layer with random dropout\n",
    "\n",
    "class ResNetFeatureExtractionWithHiddenLayer(nn.Module):\n",
    "    def __init__(self,embedding_dim = 512):\n",
    "        super(ResNetFeatureExtractionWithHiddenLayer,self).__init__()\n",
    "        resnet = resnet50(pretrained = True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.additional_layer = nn.Sequential(\n",
    "            nn.Linear(2048,embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.additional_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HiddenLayerModel = ResNetFeatureExtractionWithHiddenLayer()\n",
    "HiddenLayerModel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation Pipeline\n",
    "\n",
    "1. **Objective**: Prepares input images for model training or inference using a series of transformations.\n",
    "2. **Resizing**: Rescales the input image to a fixed size of `1024x1024` pixels.\n",
    "3. **Color Jitter**: Applies random variations in brightness, contrast, saturation, and hue to augment the dataset and improve model generalization.\n",
    "   - Brightness: Adjusted by up to 20%.\n",
    "   - Contrast: Adjusted by up to 20%.\n",
    "   - Saturation: Adjusted by up to 20%.\n",
    "   - Hue: Adjusted by up to 10%.\n",
    "4. **Normalization**: Standardizes image pixel values using the ImageNet dataset's mean (`[0.485, 0.456, 0.406]`) and standard deviation (`[0.229, 0.224, 0.225]`).\n",
    "5. **ToTensor**: Converts the image to a PyTorch tensor, scaling pixel values to the range `[0, 1]`.\n",
    "6. **Purpose**: Enhances data diversity and ensures input consistency for pretrained models like ResNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 1024)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Functionality**: The `load_image` function loads an image from the specified path, converts it to RGB format, applies the defined transformations, and adds a batch dimension.\n",
    "- **Key Operation**: It ensures compatibility with PyTorch models by transforming and batching the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Functionality**: This script defines a function `list_jpg_files_in_folder` to recursively list all `.jpg` files in a given folder, returning their names and full paths as a dictionary.\n",
    "- **Edge Case Handling**: The function checks if the folder exists and handles non-existent paths gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_jpg_files_in_folder(folder_path):\n",
    "    jpg_file_path_list = []\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder does not exists : {folder_path}\")\n",
    "        return jpg_file_path_list\n",
    "    \n",
    "    for root,_,files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".jpg\"):\n",
    "                full_path = os.path.join(root,file)\n",
    "                jpg_file_path_list.append({'name':file,'path':full_path})\n",
    "    return jpg_file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensor(file_path,model):\n",
    "    img = load_image(file_path)\n",
    "    with torch.no_grad():\n",
    "        embed = model(img)\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `get_similarity`\n",
    "\n",
    "1. **Objective**: Calculates and displays pairwise cosine similarity between image embeddings in a specified folder.\n",
    "2. **Inputs**:\n",
    "   - `folder_path`: Path to the folder containing `.jpg` images.\n",
    "   - `model`: The feature extraction model for generating image embeddings.\n",
    "3. **Process**:\n",
    "   - **Step 1**: Use `list_jpg_files_in_folder` to retrieve `.jpg` file paths in the folder.\n",
    "   - **Step 2**: For each image, generate embeddings using the `get_img_tensor` function.\n",
    "   - **Step 3**: Normalize embeddings with L2 normalization using `F.normalize`.\n",
    "   - **Step 4**: Compute cosine similarity between all pairs of embeddings.\n",
    "   - **Step 5**: Print similarity scores with image file paths.\n",
    "4. **Key Features**:\n",
    "   - **Normalization**: Ensures embeddings have unit length, making cosine similarity accurate.\n",
    "   - **Cosine Similarity**: Measures the angle between embeddings to determine similarity.\n",
    "5. **Output**: Displays similarity scores between all image pairs in the folder.\n",
    "6. **Use Case**: Ideal for tasks like identifying similar images in a dataset or verifying image uniqueness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def get_similarity(folder_path,model):\n",
    "    img_embed = []\n",
    "    # folder_path = \"./ImgFolderDataset\"\n",
    "    jpg_files = list_jpg_files_in_folder(folder_path)\n",
    "    for jpg_file in jpg_files:\n",
    "        filepath = jpg_file.get('path')\n",
    "        file_embeding = get_img_tensor(filepath,model)\n",
    "        img_embed.append({'filepath':filepath,'embed':file_embeding})\n",
    "    for img in img_embed:\n",
    "        emb1 = F.normalize(img.get('embed'),p=2,dim=1)\n",
    "        for myimg in img_embed:\n",
    "            emb2 = F.normalize(myimg.get('embed'),p=2,dim=1)\n",
    "            similarity = cosine_similarity(emb1,emb2).item()\n",
    "            print(f\"the similarity between {img.get('filepath')} and {myimg.get('filepath')} is {similarity:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the similarity between ./animal_image\\Cat\\brad1.jpg and ./animal_image\\Cat\\brad1.jpg is 1.0000\n",
      "the similarity between ./animal_image\\Cat\\brad1.jpg and ./animal_image\\Cat\\cat1.jpg is 0.7756\n",
      "the similarity between ./animal_image\\Cat\\brad1.jpg and ./animal_image\\Cat\\cat2.jpg is 0.7650\n",
      "the similarity between ./animal_image\\Cat\\brad1.jpg and ./animal_image\\Dog\\dog1.jpg is 0.6842\n",
      "the similarity between ./animal_image\\Cat\\brad1.jpg and ./animal_image\\Dog\\dog2.jpg is 0.7085\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Cat\\brad1.jpg is 0.7756\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Cat\\cat1.jpg is 1.0000\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Cat\\cat2.jpg is 0.8265\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Dog\\dog1.jpg is 0.6782\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Dog\\dog2.jpg is 0.6946\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Cat\\brad1.jpg is 0.7650\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Cat\\cat1.jpg is 0.8265\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Cat\\cat2.jpg is 1.0000\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Dog\\dog1.jpg is 0.6248\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Dog\\dog2.jpg is 0.6169\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Cat\\brad1.jpg is 0.6842\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Cat\\cat1.jpg is 0.6782\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Cat\\cat2.jpg is 0.6248\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Dog\\dog1.jpg is 1.0000\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Dog\\dog2.jpg is 0.9179\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Cat\\brad1.jpg is 0.7085\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Cat\\cat1.jpg is 0.6946\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Cat\\cat2.jpg is 0.6169\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Dog\\dog1.jpg is 0.9179\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Dog\\dog2.jpg is 1.0000\n"
     ]
    }
   ],
   "source": [
    "folder_path1 = './animal_image'\n",
    "get_similarity(folder_path1,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Cat\\cat1.jpg is 1.0000\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Cat\\cat2.jpg is 0.8801\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Dog\\dog1.jpg is 0.7674\n",
      "the similarity between ./animal_image\\Cat\\cat1.jpg and ./animal_image\\Dog\\dog2.jpg is 0.7416\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Cat\\cat1.jpg is 0.8801\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Cat\\cat2.jpg is 1.0000\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Dog\\dog1.jpg is 0.6783\n",
      "the similarity between ./animal_image\\Cat\\cat2.jpg and ./animal_image\\Dog\\dog2.jpg is 0.6738\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Cat\\cat1.jpg is 0.7674\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Cat\\cat2.jpg is 0.6783\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Dog\\dog1.jpg is 1.0000\n",
      "the similarity between ./animal_image\\Dog\\dog1.jpg and ./animal_image\\Dog\\dog2.jpg is 0.9222\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Cat\\cat1.jpg is 0.7416\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Cat\\cat2.jpg is 0.6738\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Dog\\dog1.jpg is 0.9222\n",
      "the similarity between ./animal_image\\Dog\\dog2.jpg and ./animal_image\\Dog\\dog2.jpg is 1.0000\n"
     ]
    }
   ],
   "source": [
    "get_similarity(folder_path1,HiddenLayerModel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
